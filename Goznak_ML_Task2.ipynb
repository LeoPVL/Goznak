{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Goznak_ML_Task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoPVL/Goznak/blob/main/Goznak_ML_Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx0HKLgC5Guq",
        "outputId": "4ac0c2f7-b763-4569-a30c-43936f401ef7"
      },
      "source": [
        "import librosa # for mel-spectrogram estimation\n",
        "!pip install soundfile\n",
        "import soundfile # for opening .flac audio\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import cv2\n",
        "from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D,Cropping2D,concatenate,ZeroPadding2D\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNzLlWtHCiWx"
      },
      "source": [
        "def _floats_feature(value):\n",
        "   return tf.train.Feature(float_list=tf.train.FloatList(value=value.reshape(-1)))\n",
        "\n",
        "def serialize_example(feature0, feature1):\n",
        "    feature = {\n",
        "        'image': _floats_feature(feature0),\n",
        "        'target': _floats_feature(feature1)\n",
        "    }\n",
        "    example_proto = tf.train.Example(features = tf.train.Features(feature = feature))\n",
        "    return example_proto.SerializeToString()\n",
        "\n",
        "def read_file(file_path):\n",
        "    arr = np.load(file_path)\n",
        "    img = arr.T\n",
        "    return img\n",
        "\n",
        "def get_tf_records(directory,file_name,SIZE = (80,48),records_count = None):\n",
        "    print('getting tf records ', file_name)\n",
        "    clean_paths = [x for x in pathlib.Path(directory+'clean/').rglob('*.npy')]\n",
        "    noisy_paths = [x for x in pathlib.Path(directory+'noisy/').rglob('*.npy')]\n",
        "\n",
        "    print('Found ',len(noisy_paths),' records.')\n",
        "    if records_count is None:\n",
        "      clean_paths = sorted(clean_paths)\n",
        "      noisy_paths = sorted(noisy_paths)\n",
        "    else:\n",
        "      clean_paths = sorted(clean_paths)[:records_count]\n",
        "      noisy_paths = sorted(noisy_paths)[:records_count]\n",
        "    i=0\n",
        "    sample_size = SIZE[1] \n",
        "    with tf.io.TFRecordWriter(directory+file_name) as writer:\n",
        "        while i < len(noisy_paths):\n",
        "                if ((i+1)%1000 == 0)and(i!=0):\n",
        "                  print(i,' records recorded')\n",
        "                noisy = read_file(str(noisy_paths[i]))\n",
        "                clean = read_file(str(clean_paths[i]))\n",
        "                noise = noisy - clean\n",
        "                noisylen = noisy.shape[1]\n",
        "\n",
        "\n",
        "                samples_num = noisylen//sample_size+1\n",
        "                padding = np.zeros((size[0],(size[1]*(samples_num)-noisylen)))\n",
        "                noisy = np.concatenate([noisy,padding],axis = 1)\n",
        "                noise = np.concatenate([noise,padding],axis = 1)\n",
        "                for k in range(0,samples_num):\n",
        "                  sample = noisy[:,k*sample_size:(k+1)*sample_size]\n",
        "                  X = sample\n",
        "                  y = noise[:,k*sample_size:(k+1)*sample_size]\n",
        "\n",
        "                  example = serialize_example(\n",
        "                      X, y\n",
        "                  )\n",
        "                  writer.write(example)\n",
        "\n",
        "                i+=1\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULuX6msLC_Ih"
      },
      "source": [
        "def read_tfrecord(example):\n",
        "    TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([*SIZE], dtype=tf.float32), \n",
        "        \n",
        "        \"target\": tf.io.FixedLenFeature([*SIZE], dtype=tf.float32)\n",
        "        }\n",
        "    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "    image = example['image']\n",
        "    target = example['target']\n",
        "    return image, target\n",
        "def load_dataset(filename):\n",
        "    dataset = tf.data.TFRecordDataset(filename)\n",
        "    dataset = dataset.map(read_tfrecord) \n",
        "    return dataset\n",
        "def arcface_format(image, target):\n",
        "    return {'inp': image},target\n",
        "\n",
        "def get_dataset(filenames,batch_size):\n",
        "    dataset = load_dataset(filenames)\n",
        "    dataset = dataset.map(arcface_format)\n",
        "    dataset = dataset.repeat() \n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aaxBLgMSjWJ"
      },
      "source": [
        "def get_crop_shape(target, refer):\n",
        "    \n",
        "    cw = (target.get_shape()[2] - refer.get_shape()[2])\n",
        "    assert (cw >= 0)\n",
        "    if cw % 2 != 0:\n",
        "        cw1, cw2 = cw // 2, cw // 2 + 1\n",
        "    else:\n",
        "        cw1, cw2 = cw // 2, cw // 2\n",
        "    ch = (target.get_shape()[1] - refer.get_shape()[1])\n",
        "    assert (ch >= 0)\n",
        "    if ch % 2 != 0:\n",
        "        ch1, ch2 = ch // 2, ch // 2 + 1\n",
        "    else:\n",
        "        ch1, ch2 = ch // 2, ch // 2\n",
        "\n",
        "    return (ch1, ch2), (cw1, cw2)\n",
        "\n",
        "def get_encoder(img_shape):\n",
        "    \n",
        "    inp = Input(shape=img_shape)\n",
        "    conv1 = Conv2D(64, (5, 5), activation='relu', padding='same', data_format=\"channels_last\", name='conv1_1')(inp)\n",
        "    conv1 = Conv2D(64, (5, 5), activation='relu', padding='same', data_format=\"channels_last\", name='conv1_2')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", name='pool1')(conv1)\n",
        "    conv2 = Conv2D(96, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv2_1')(pool1)\n",
        "    conv2 = Conv2D(96, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv2_2')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", name='pool2')(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv3_1')(pool2)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv3_2')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", name='pool3')(conv3)\n",
        "\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv4_1')(pool3)\n",
        "    conv4 = Conv2D(256, (4, 4), activation='relu', padding='same', data_format=\"channels_last\", name='conv4_2')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", name='pool4')(conv4)\n",
        "\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv5_1')(pool4)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv5_2')(conv5)\n",
        "    \n",
        "    return conv5,conv4,conv3,conv2,conv1,inp\n",
        "\n",
        "def get_decoder(convs):\n",
        "    \n",
        "    conv5,conv4,conv3,conv2,conv1,inputs = convs\n",
        "    \n",
        "    up_conv5 = UpSampling2D(size=(2, 2), data_format=\"channels_last\", name='up_conv5')(conv5)\n",
        "    ch, cw = get_crop_shape(conv4, up_conv5)\n",
        "    crop_conv4 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\", name='crop_conv4')(conv4)\n",
        "    up6 = concatenate([up_conv5, crop_conv4])\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv6_1')(up6)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv6_2')(conv6)\n",
        "\n",
        "    up_conv6 = UpSampling2D(size=(2, 2), data_format=\"channels_last\", name='up_conv6')(conv6)\n",
        "    ch, cw = get_crop_shape(conv3, up_conv6)\n",
        "    crop_conv3 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\", name='crop_conv3')(conv3)\n",
        "    up7 = concatenate([up_conv6, crop_conv3])\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv7_1')(up7)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv7_2')(conv7)\n",
        "\n",
        "    up_conv7 = UpSampling2D(size=(2, 2), data_format=\"channels_last\", name='up_conv7')(conv7)\n",
        "    ch, cw = get_crop_shape(conv2, up_conv7)\n",
        "    crop_conv2 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\", name='crop_conv2')(conv2)\n",
        "    up8 = concatenate([up_conv7, crop_conv2])\n",
        "    conv8 = Conv2D(96, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv8_1')(up8)\n",
        "    conv8 = Conv2D(96, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv8_2')(conv8)\n",
        "\n",
        "    up_conv8 = UpSampling2D(size=(2, 2), data_format=\"channels_last\", name='up_conv8')(conv8)\n",
        "    ch, cw = get_crop_shape(conv1, up_conv8)\n",
        "    crop_conv1 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\", name='crop_conv1')(conv1)\n",
        "    up9 = concatenate([up_conv8, crop_conv1])\n",
        "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv9_1')(up9)\n",
        "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format=\"channels_last\", name='conv9_2')(conv9)\n",
        "\n",
        "    ch, cw = get_crop_shape(inputs, conv9)\n",
        "    conv9 = ZeroPadding2D(padding=(ch, cw), data_format=\"channels_last\", name='conv9_3')(conv9)\n",
        "    conv10 = Conv2D(1, (1, 1), activation='tanh', data_format=\"channels_last\", name='out')(conv9)\n",
        "    \n",
        "    return conv10\n",
        "    \n",
        "\n",
        "def get_unet(img_shape = (200,200,1)):\n",
        "\n",
        "    enc = get_encoder(img_shape)\n",
        "    \n",
        "    dec = get_decoder(enc)\n",
        "    \n",
        "    model = Model(inputs=enc[-1], outputs=dec)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS42hCZS4VB0"
      },
      "source": [
        "def inference_with_pics(noisy_path,clean_path,path_to_model,size):\n",
        "  X = []\n",
        "  y = []\n",
        "  model = tf.keras.models.load_model(path_to_model)\n",
        "  sample_size = size[1] \n",
        "  noisy = read_file(str(noisy_path))\n",
        "  clean = read_file(str(clean_path))\n",
        "  noisylen = noisy.shape[1]\n",
        "\n",
        "  samples_num = noisylen//sample_size+1\n",
        "  padding = np.zeros((size[0],(size[1]*(samples_num)-noisylen)))\n",
        "  noisy = np.concatenate([noisy,padding],axis = 1)\n",
        "  for k in range(0,samples_num):\n",
        "    sample = noisy[:,k*sample_size:(k+1)*sample_size]\n",
        "    X+= [sample]\n",
        "  \n",
        "  X = (np.array(X).reshape(samples_num, *size, 1))\n",
        "\n",
        "  pred = model(X)\n",
        "  pred_noise = np.concatenate([x for x in pred], axis = 1)\n",
        "  \n",
        "  pred_noise = pred_noise.reshape(size[0],size[1]*(samples_num))\n",
        "  result = noisy-pred_noise\n",
        "  print('noisy')\n",
        "  plt.imshow(noisy)\n",
        "  plt.show()\n",
        "  print('clean')\n",
        "  plt.imshow(np.concatenate([clean,padding],axis = 1))\n",
        "  plt.show()\n",
        "  print('pred')\n",
        "  plt.imshow(result)\n",
        "  plt.show()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adbeOZ-kbkWR"
      },
      "source": [
        "# clean_path = '/content/drive/MyDrive/train/val/clean/1166/1166_14986_1166-14986-0024.npy'\n",
        "# noisy_path = '/content/drive/MyDrive/train/val/noisy/1166/1166_14986_1166-14986-0024.npy'\n",
        "# inference_with_pics(noisy_path,clean_path,TRAIN_PATH+'denoising_model.h5')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfrGmUQccd9q"
      },
      "source": [
        "# clean_path = '/content/drive/MyDrive/train/val/clean/245/245_122647_245-122647-0070.npy'\n",
        "# noisy_path = '/content/drive/MyDrive/train/val/noisy/245/245_122647_245-122647-0070.npy'\n",
        "# inference_with_pics(noisy_path,clean_path,TRAIN_PATH+'denoising_model.h5')\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnkhFys28Ttd"
      },
      "source": [
        "def train(train_path,VAL_PATH,):\n",
        "  \n",
        "  batch_size = 100\n",
        "  \n",
        "  # get_tf_records(train_path,'train.tfrec',size = size)\n",
        "  # get_tf_records(VAL_PATH,'val.tfrec',size = size)\n",
        "  \n",
        "  train_dataset = get_dataset(train_path + 'train.tfrec',batch_size)\n",
        "  val_dataset = get_dataset(VAL_PATH + 'val.tfrec',batch_size)\n",
        "\n",
        "  model = get_unet([*SIZE,1])\n",
        "  opt = tf.keras.optimizers.Adam(lr=(1e-4))\n",
        "  model.compile(optimizer=opt,\n",
        "              loss='MeanSquaredError',\n",
        "              metrics=['MSE','CosineSimilarity'])\n",
        "  \n",
        "  for _ in range(10):\n",
        "    model.fit(train_dataset,\n",
        "            steps_per_epoch = 600, \n",
        "            validation_data=val_dataset,\n",
        "            validation_steps = 100,\n",
        "            epochs = 10)\n",
        "    model.save(train_path+'denoising_model.h5')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UofSymqpPeWs"
      },
      "source": [
        "def inference(noisy_file_path,path_to_model):\n",
        "\n",
        "  model = tf.keras.models.load_model(path_to_model+'denoising_model.h5')\n",
        "  X = []\n",
        "  y = []\n",
        "  sample_size = SIZE[1]\n",
        "  noisy = read_file(str(noisy_file_path))\n",
        "  noisylen = noisy.shape[1]\n",
        "\n",
        "  samples_num = noisylen//sample_size+1\n",
        "  padding = np.zeros((SIZE[0],(SIZE[1]*(samples_num)-noisylen)))\n",
        "  noisy = np.concatenate([noisy,padding],axis = 1)\n",
        "  for k in range(0,samples_num):\n",
        "    sample = noisy[:,k*sample_size:(k+1)*sample_size]\n",
        "    X+= [sample]\n",
        "  \n",
        "  X = (np.array(X).reshape(samples_num, *SIZE, 1))\n",
        "\n",
        "  pred = model(X)\n",
        "  pred_noise = np.concatenate([x for x in pred], axis = 1)\n",
        "  \n",
        "  pred_noise = pred_noise.reshape(SIZE[0],SIZE[1]*(samples_num))\n",
        "\n",
        "  return pred_noise[:,:noisylen].T"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL6L6b87WthJ",
        "outputId": "05d5efa0-fab0-4cf5-92bb-8fa61f8eba64"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "SIZE = (80,48)\n",
        "TRAIN_PATH = '/content/drive/My Drive/train/train/train/'\n",
        "VAL_PATH = '/content/drive/MyDrive/train/val/'\n",
        "train(TRAIN_PATH,VAL_PATH)\n",
        "\n",
        "noisy_path = VAL_PATH+'noisy/1084/1084_139230_1084-139230-0002.npy'\n",
        "clean_mel = inference(noisy_path,TRAIN_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch 1/10\n",
            "  2/600 [..............................] - ETA: 1:11 - loss: 0.0961 - MSE: 0.0961 - cosine_similarity: 0.4403WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0787s vs `on_train_batch_end` time: 0.1580s). Check your callbacks.\n",
            "158/600 [======>.......................] - ETA: 1:48 - loss: 0.0645 - MSE: 0.0645 - cosine_similarity: 0.6687"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}